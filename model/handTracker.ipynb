{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "856ff1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8233229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1643279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import uuid\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from spellchecker import SpellChecker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de558a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ea7f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_DIR = './aslalphabetcnnmodel1'\n",
    "# MODEL_PATH = MODEL_DIR + '/ann-model98.h5'\n",
    "# MODEL_WEIGHTS_PATH = MODEL_DIR + '/ann-model98.weights.h5'\n",
    "\n",
    "\n",
    "MODEL_DIR = './akram/Models'\n",
    "MODEL_WEIGHTS_DIR = './akram/Weights'\n",
    "MODEL_PATH = MODEL_DIR + '/ann-model-99.35.h5'\n",
    "MODEL_WEIGHTS_PATH = MODEL_WEIGHTS_DIR + '/ann-model-99.35.weights.h5'\n",
    "CLASSES = ['A',\n",
    " 'B',\n",
    " 'C',\n",
    " 'D',\n",
    " 'E',\n",
    " 'F',\n",
    " 'G',\n",
    " 'H',\n",
    " 'I',\n",
    " 'J',\n",
    " 'K',\n",
    " 'L',\n",
    " 'M',\n",
    " 'N',\n",
    " 'O',\n",
    " 'P',\n",
    " 'Q',\n",
    " 'R',\n",
    " 'S',\n",
    " ' ',\n",
    " 'T',\n",
    " 'U',\n",
    " 'V',\n",
    " 'W',\n",
    " 'X',\n",
    " 'Y',\n",
    " 'Z']\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "697477b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_image(image):\n",
    "#     sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "#     return sobely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c79bfde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_from_disk():\n",
    "    '''A convenience method for re-running certain parts of the\n",
    "    analysis locally without refitting all the data.'''\n",
    "    model_file = Path(MODEL_PATH)\n",
    "    model_weights_file = Path(MODEL_WEIGHTS_PATH)\n",
    "    \n",
    "    print(model_weights_file)\n",
    "    \n",
    "                      \n",
    "    if model_file.is_file() and model_weights_file.is_file():\n",
    "        print('Retrieving model from disk...')\n",
    "        model = load_model(model_file.__str__())\n",
    "                      \n",
    "        print('Loading ANN model weights from disk...')\n",
    "        model.load_weights(model_weights_file)\n",
    "        print(\"=== modelloaded===\")\n",
    "        return model\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "747355c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akram\\Weights\\ann-model-99.35.weights.h5\n",
      "Retrieving model from disk...\n",
      "Loading ANN model weights from disk...\n",
      "=== modelloaded===\n"
     ]
    }
   ],
   "source": [
    "signDetector = load_model_from_disk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a8ca8c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'akram'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"akram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd98a457",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "H\n",
      "H\n",
      "HE\n",
      "HE\n",
      "HEL\n",
      "HELC\n",
      "espace\n",
      "passer par le correcteur  HELC\n",
      "help\n",
      "espace\n",
      "passer par le correcteur  help\n",
      "help\n",
      "espace\n",
      "passer par le correcteur  help\n",
      "help\n",
      "help  \n",
      "help  \n",
      "help  \n",
      "help  \n",
      "help  \n",
      "help  \n",
      "help  H\n",
      "help  H\n",
      "help  HE\n",
      "help  HE\n",
      "help  HEL\n",
      "help  HEL\n",
      "help  HELO\n",
      "help  HELO\n",
      "help  HELO\n",
      "espace\n",
      "passer par le correcteur  help\n",
      "help\n",
      "passer par le correcteur  HELO\n",
      "HELO\n",
      "espace\n",
      "passer par le correcteur  help\n",
      "help\n",
      "passer par le correcteur  HELO\n",
      "HELO\n",
      "help  HELO  \n",
      "help  HELO  \n",
      "help  HELO  \n",
      "help  HELO  \n",
      "help  HELO  \n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  B\n",
      "help  HELO  BA\n",
      "help  HELO  BA\n",
      "help  HELO  BAB\n",
      "help  HELO  BAB\n",
      "help  HELO  BABL\n",
      "help  HELO  BABL\n",
      "espace\n",
      "passer par le correcteur  help\n",
      "help\n",
      "passer par le correcteur  HELO\n",
      "HELO\n",
      "passer par le correcteur  BABL\n",
      "baby\n",
      "help  HELO  baby  \n",
      "help  HELO  baby  \n",
      "help  HELO  baby  \n",
      "help  HELO  baby  A\n",
      "help  HELO  baby  A\n",
      "help  HELO  baby  A\n",
      "help  HELO  baby  A\n",
      "help  HELO  baby  AB\n",
      "help  HELO  baby  AB\n",
      "help  HELO  baby  AB\n",
      "help  HELO  baby  AB\n",
      "help  HELO  baby  ABC\n",
      "help  HELO  baby  ABC\n",
      "help  HELO  baby  ABCO\n",
      "help  HELO  baby  ABCO\n",
      "help  HELO  baby  ABCO\n",
      "espace\n",
      "passer par le correcteur  help\n",
      "help\n",
      "passer par le correcteur  HELO\n",
      "HELO\n",
      "passer par le correcteur  baby\n",
      "baby\n",
      "passer par le correcteur  ABCO\n",
      "abo\n",
      "help  HELO  baby  abo  L\n"
     ]
    }
   ],
   "source": [
    "# cap = cv2.VideoCapture(\"ASL_test_1.mp4\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "_, frame = cap.read()\n",
    "h, w, c = frame.shape\n",
    "\n",
    "i = 0\n",
    "text = ''\n",
    "\n",
    "with mp_hands.Hands(min_detection_confidence=0.4, min_tracking_confidence=0.3,max_num_hands=1) as hands: \n",
    "    while cap.isOpened():\n",
    "        i = i + 1\n",
    "        ret, frame = cap.read()\n",
    "        last_char= \"\"\n",
    "        \n",
    "        # BGR 2 RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Flip on horizontal\n",
    "        #j'ai enlever cette instruction pour esseyer d'ajuster la video que j'ai enregistrer suivant le model\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # Set flag\n",
    "        image.flags.writeable = False\n",
    "        \n",
    "        # Detections\n",
    "        \n",
    "        croppedImage = cv2.resize(image,(600, 600))\n",
    "        \n",
    "        results = hands.process(croppedImage)\n",
    "      \n",
    "        # Set flag to true\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        # RGB 2 BGR\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        image = cv2.cvtColor(croppedImage,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  \n",
    "        # org\n",
    "        org = (50, 50)\n",
    "\n",
    "        # fontScale\n",
    "        fontScale = 1\n",
    "\n",
    "        # Blue color in BGR\n",
    "        color = (255, 0, 0)\n",
    "\n",
    "        # Line thickness of 2 px\n",
    "        thickness = 2\n",
    "        \n",
    "        # Detections\n",
    "        # print(results)\n",
    "        \n",
    "        x = []\n",
    "        # Rendering results\n",
    "        if results.multi_hand_landmarks:\n",
    "            for num, hand in enumerate(results.multi_hand_landmarks):\n",
    "#                 x_max = 0\n",
    "#                 y_max = 0\n",
    "#                 x_min = w\n",
    "#                 y_min = h\n",
    "                landmarksForImage = [[lm.x,lm.y,lm.z] for lm in hand.landmark]   \n",
    "#                 x, y = int(lm.x * w), int(lm.y * h)\n",
    "#                 if x > x_max:\n",
    "#                     x_max = x\n",
    "#                 if x < x_min:\n",
    "#                     x_min = x\n",
    "#                 if y > y_max:\n",
    "#                     y_max = y\n",
    "#                 if y < y_min:\n",
    "#                     y_min = y\n",
    "#                 cv2.rectangle(image, (x_min - 25, y_min - 25), (x_max + 25, y_max + 25), (0, 255, 0), 2)\n",
    "#                 img1 = image[x_min:x_max,y_min:y_max]               \n",
    "                mp_drawing.draw_landmarks(image, hand, mp_hands.HAND_CONNECTIONS, \n",
    "                                        mp_drawing.DrawingSpec(color=(121, 22, 76), thickness=2, circle_radius=4),\n",
    "                                        mp_drawing.DrawingSpec(color=(250, 44, 250), thickness=2, circle_radius=2),\n",
    "                                       )\n",
    "            x.append(landmarksForImage)\n",
    "            if i % 10 == 0 :\n",
    "    #                 img = preprocess_image(img1)\n",
    "    #                 croppedImage = cv2.resize(img,(64, 64))\n",
    "    #                 prediction = signDetector.predict(x.reshape(-1, 64, 64, 3))\n",
    "                prediction = signDetector.predict(x)   \n",
    "                r = np.argmax(prediction, axis=1)\n",
    "                if (CLASSES[r[0]] == \" \" and prediction[0][np.argmax(prediction)] >0.8):\n",
    "                    print(\"espace\")\n",
    "                    txt = text.split(\"  \")\n",
    "                    text = \"\"\n",
    "                    for j in txt:\n",
    "                        if j!=\"\" and len(j)>1:   \n",
    "                            print(\"passer par le correcteur \",j)\n",
    "                            text = text + spell.correction(j) + \"  \"\n",
    "                            print( spell.correction(j))\n",
    "                        elif len(j)==1: \n",
    "                            text = text + j + \"  \"\n",
    "\n",
    "                else :\n",
    "                    if  prediction[0][np.argmax(prediction)] >0.6: \n",
    "\n",
    "                        if (CLASSES[r[0]]!=text[len(text)-1:]): \n",
    "                            text = text + CLASSES[r[0]]\n",
    "    #                         print(CLASSES[r[0]])\n",
    "                   \n",
    "                    \n",
    "                    print(text)\n",
    "        \n",
    "        cv2.putText(image,text,org, font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "\n",
    "        \n",
    "        cv2.imshow('Hand Tracking', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41bc55",
   "metadata": {},
   "source": [
    "## text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cad21604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'W  OC  cocolo  wole  '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dfa40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
